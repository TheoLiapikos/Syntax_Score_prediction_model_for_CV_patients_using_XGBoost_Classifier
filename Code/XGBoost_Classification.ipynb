{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## XGBoost Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basic Directories\n",
    "# Current directory (code)\n",
    "cwd = os.getcwd()\n",
    "# Parent directory (root directory for all folders)\n",
    "parent = Path(cwd).parent\n",
    "# Modules directory\n",
    "modules_dir = os.path.join(cwd,'modules')\n",
    "# Dataset directory\n",
    "dsets_dir = os.path.join(parent,'Dataset')\n",
    "# Analysis Results Data Directory\n",
    "anres_data_dir = os.path.join(parent,'Analysis_results')\n",
    "if not os.path.exists(anres_data_dir):\n",
    "    os.makedirs(anres_data_dir)\n",
    "# Evaluation Results Directory\n",
    "res_dir = os.path.join(parent,'Evaluation_Results')\n",
    "if not os.path.exists(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "# Directory to store collected experimental data\n",
    "res_raw_dir = os.path.join(res_dir,'Collect_Analysis_results')\n",
    "if not os.path.exists(res_raw_dir):\n",
    "    os.makedirs(res_raw_dir)\n",
    "# Directory to store results and plots for Statistical Analysis\n",
    "res_stat_dir = os.path.join(res_dir, 'Statistical_tests')\n",
    "if not os.path.exists(res_stat_dir):\n",
    "    os.makedirs(res_stat_dir)\n",
    "\n",
    "# Include modules' dir into system to import modules\n",
    "sys.path.append(modules_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports from modules\n",
    "from Preprocess_dataset import Preprocess_dataset\n",
    "from Dataset_CLF_analysis import Dataset_CLF_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PreProcess RAW dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Link to dataset with RAW data\n",
    "dset_n = 'RAW_data.xlsx'\n",
    "dset_lnk = os.path.join(dsets_dir, dset_n)\n",
    "\n",
    "### Preprocess RAW data\n",
    "ppdset = Preprocess_dataset(dset_lnk)\n",
    "data_df = ppdset.preproc_dset\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analyse datasets with XGBoost Classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a Dataset_ML_analysis object to control all functionality\n",
    "dset = Dataset_CLF_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define dependent and independent variables\n",
    "y = data_df['Syntax Score']\n",
    "X = data_df.drop(['Syntax Score'], axis=1)\n",
    "### Transform dependent variable's values to create 2 groups\n",
    "# Healthy (SS=0->0) vs Patients (SS>0->1)\n",
    "y[y>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set analysis parameters\n",
    "# Metric to use\n",
    "metric_n = 'logloss'  # 'logloss', 'ACCU'\n",
    "# Number of predictions cv iterations\n",
    "pred_splits = 10\n",
    "# Number of optimization cv iterations\n",
    "opt_cv = 10\n",
    "# Number of random parameters sets to examine during optimization\n",
    "opt_iters = 100\n",
    "# Number of analysis iterations\n",
    "n = 10\n",
    "\n",
    "# Probas threshold for groups\n",
    "thresh = 0.5\n",
    "\n",
    "# Methods to be used in analysis\n",
    "use_models = ['XGBClf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Perform analysis of dataset\n",
    "dset.analyse_datasets(X, y, anres_data_dir, use_models=use_models, metric_n=metric_n, \n",
    "                    pred_splits=pred_splits, opt_cv=opt_cv, opt_iters=opt_iters, n=n,\n",
    "                    thresh=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect RAW Experimental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to collect all analysis results\n",
    "dset.collect_raw_res_data(anres_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store resulting dictionary to a pickle file and an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results (pickle and excel)\n",
    "rd_dic_fn = 'Collected_experimental_data.xlsx'\n",
    "rd_dic_fn_lnk = os.path.join(res_raw_dir, rd_dic_fn)\n",
    "dset.export_dict_to_file(dset.raw_data_dic, rd_dic_fn_lnk, kl=1, unif_col_widths=1)\n",
    "\n",
    "# Export results to pickle (The whole object is stored)\n",
    "rd_dic_fn = 'Collected_experimental_data.pickle'\n",
    "rd_dic_fn_lnk = os.path.join(res_raw_dir, rd_dic_fn)\n",
    "dset.export_dict_to_file(dset, rd_dic_fn_lnk, kl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dset.analyze_experimental_data(res_raw_dir, res_stat_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
